We introduce a causal-faithfulness metric $F(\E)$ that quantifies whether post-hoc explanations capture true causal influence of input features on model predictions. The metric is model-agnostic and modality-agnostic, built on principled feature masking and Monte Carlo estimation with uncertainty quantification. We evaluate across text (SST-2 with BERT; WikiText-2 with GPT-2) and a synthetic tabular setting, compare multiple explainers (Integrated Gradients, SHAP, LIME, Random), and validate using ROAR removal-and-retrain correlations. Our results show $F(\E)$ strongly differentiates informed from random explainers, exhibits consistency across datasets, and aligns with ROAR. Statistical tests (paired t-tests with corrections, nonparametrics), effect sizes, and bootstrap confidence intervals support the significance and robustness of findings. We provide theoretical validation figures demonstrating monotonicity and normalization, and release code and artifacts to enable full reproducibility.

