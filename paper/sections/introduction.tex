Explainable machine learning requires evaluations that reflect causal influence rather than mere association. We propose a causal-faithfulness metric $\Fscore$ that measures whether an explainerâ€™s attributions align with the effect of interventions on model predictions. Our contributions are: (1) a modality-agnostic metric grounded in principled feature masking, (2) comprehensive empirical validation on text and tabular data with BERT and GPT-2 \citep{devlin2019bert,radford2019gpt2} across GLUE/SST-2 and WikiText-2 \citep{wang2018glue,merity2016wikitext}, and (3) theoretical and statistical analysis demonstrating robustness and consistency.

